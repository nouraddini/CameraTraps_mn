{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://zenodo.org/records/13357337/files/md_v5a.0.0.pt?download=1\" to /home/mo/.cache/torch/hub/checkpoints/md_v5a.0.0.pt\n",
      "100%|██████████| 268M/268M [00:04<00:00, 64.5MB/s] \n",
      "Fusing layers... \n",
      "Fusing layers... \n",
      "Model summary: 733 layers, 140054656 parameters, 0 gradients, 208.8 GFLOPs\n",
      "Model summary: 733 layers, 140054656 parameters, 0 gradients, 208.8 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "from PytorchWildlife.models import detection as pw_detection\n",
    "\n",
    "detection_model = pw_detection.MegaDetectorV5()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "Fusing layers... \n",
      "Model summary: 733 layers, 140054656 parameters, 0 gradients, 208.8 GFLOPs\n",
      "Model summary: 733 layers, 140054656 parameters, 0 gradients, 208.8 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "Fusing layers... \n",
      "Model summary: 733 layers, 140054656 parameters, 0 gradients, 208.8 GFLOPs\n",
      "Model summary: 733 layers, 140054656 parameters, 0 gradients, 208.8 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: Type - <class 'list'>, Length - 3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from PytorchWildlife.models import detection as pw_detection\n",
    "from PytorchWildlife.data import datasets as pw_data\n",
    "from PytorchWildlife.data import transforms as pw_trans\n",
    "from torch.utils.data import DataLoader\n",
    "import PytorchWildlife.utils as pw_utils\n",
    "\n",
    "# Set up directories\n",
    "tgt_folder_path = '/media/mo/nvme0n1/MDv5_v6_test_HG'\n",
    "output_path = '/media/mo/nvme0n1/MDv5_test_HG_separated_subfolder_1'\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Initialize the detection model\n",
    "detection_model = pw_detection.MegaDetectorV5()\n",
    "\n",
    "# Define the dataset and data loader\n",
    "dataset = pw_data.DetectionImageFolder(\n",
    "    tgt_folder_path,\n",
    "    transform=pw_trans.MegaDetector_v5_Transform(\n",
    "        target_size=detection_model.IMAGE_SIZE,\n",
    "        stride=detection_model.STRIDE\n",
    "    )\n",
    ")\n",
    "loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Process images in batches\n",
    "for batch_idx, batch in enumerate(loader):\n",
    "    print(f\"Batch {batch_idx}: Type - {type(batch)}, Length - {len(batch)}\")\n",
    "    #break\n",
    "    \n",
    "    images, image_paths, img_sizes = zip(*batch)\n",
    "    # Ensure all images have the same dimensions\n",
    "    for img in images:\n",
    "        assert img.shape == images[0].shape, \"Inconsistent image dimensions in the batch.\"\n",
    "    images = torch.stack(images)\n",
    "    # Unpack the batch\n",
    "    images, image_paths, img_sizes = zip(*batch)\n",
    "\n",
    "    # Stack images into a single tensor\n",
    "    images = torch.stack(images)\n",
    "\n",
    "    # Perform detection on the current batch\n",
    "    results = detection_model.batch_image_detection(images)\n",
    "\n",
    "    # Save detection results for the current batch\n",
    "    batch_output_path = os.path.join(output_path, f'batch_{batch_idx}')\n",
    "    os.makedirs(batch_output_path, exist_ok=True)\n",
    "\n",
    "    # Save annotated images\n",
    "    pw_utils.save_detection_images(results, batch_output_path)\n",
    "\n",
    "    # Save detection results in JSON format\n",
    "    json_file = os.path.join(batch_output_path, 'detection_results.json')\n",
    "    pw_utils.save_detection_json(\n",
    "        results, json_file,\n",
    "        categories=detection_model.CLASS_NAMES\n",
    "    )\n",
    "\n",
    "    # Separate positive and negative detections\n",
    "    pw_utils.detection_folder_separation(\n",
    "        json_file, tgt_folder_path, batch_output_path, threshold=0.5\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not Tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m images \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39munsqueeze(image, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Perform detection\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mdetection_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_image_detection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Save detection results\u001b[39;00m\n\u001b[1;32m     12\u001b[0m batch_output_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_path, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-wildlife/lib/python3.8/site-packages/PytorchWildlife/models/detection/ultralytics_based/yolov5_base.py:151\u001b[0m, in \u001b[0;36mYOLOV5Base.batch_image_detection\u001b[0;34m(self, data_path, batch_size, conf_thres, id_strip)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbatch_image_detection\u001b[39m(\u001b[38;5;28mself\u001b[39m, data_path, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, conf_thres\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, id_strip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    132\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m    Perform detection on a batch of images.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m        list: List of detection results for all images.\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mpw_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDetectionImageFolder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# Creating a DataLoader for batching and parallel processing of the images\u001b[39;00m\n\u001b[1;32m    157\u001b[0m     loader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[1;32m    158\u001b[0m                         pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-wildlife/lib/python3.8/site-packages/PytorchWildlife/data/datasets.py:46\u001b[0m, in \u001b[0;36mDetectionImageFolder.__init__\u001b[0;34m(self, image_dir, transform)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_dir \u001b[38;5;241m=\u001b[39m image_dir\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;241m=\u001b[39m transform\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dp, f) \u001b[38;5;28;01mfor\u001b[39;00m dp, dn, filenames \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mwalk(image_dir) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m filenames \u001b[38;5;28;01mif\u001b[39;00m is_image_file(f)] \u001b[38;5;66;03m# dp: directory path, dn: directory name, f: filename\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-wildlife/lib/python3.8/site-packages/PytorchWildlife/data/datasets.py:46\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_dir \u001b[38;5;241m=\u001b[39m image_dir\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;241m=\u001b[39m transform\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dp, f) \u001b[38;5;28;01mfor\u001b[39;00m dp, dn, filenames \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mwalk(image_dir) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m filenames \u001b[38;5;28;01mif\u001b[39;00m is_image_file(f)] \u001b[38;5;66;03m# dp: directory path, dn: directory name, f: filename\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-wildlife/lib/python3.8/os.py:339\u001b[0m, in \u001b[0;36mwalk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwalk\u001b[39m(top, topdown\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, onerror\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, followlinks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    281\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Directory tree generator.\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \n\u001b[1;32m    283\u001b[0m \u001b[38;5;124;03m    For each directory in the directory tree rooted at top (including top\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    337\u001b[0m \n\u001b[1;32m    338\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 339\u001b[0m     top \u001b[38;5;241m=\u001b[39m \u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m     dirs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    341\u001b[0m     nondirs \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not Tensor"
     ]
    }
   ],
   "source": [
    "for idx in range(len(dataset)):\n",
    "    # Get a single item\n",
    "    image, image_path, img_size = dataset[idx]\n",
    "\n",
    "    # Prepare the image for batch processing\n",
    "    images = torch.unsqueeze(image, dim=0)\n",
    "\n",
    "    # Perform detection\n",
    "    results = detection_model.batch_image_detection(images)\n",
    "\n",
    "    # Save detection results\n",
    "    batch_output_path = os.path.join(output_path, f'image_{idx}')\n",
    "    os.makedirs(batch_output_path, exist_ok=True)\n",
    "    pw_utils.save_detection_images(results, batch_output_path)\n",
    "\n",
    "    # Save JSON\n",
    "    json_file = os.path.join(batch_output_path, 'detection_results.json')\n",
    "    pw_utils.save_detection_json(\n",
    "        results, json_file,\n",
    "        categories=detection_model.CLASS_NAMES\n",
    "    )\n",
    "\n",
    "    # Separate positive and negative detections\n",
    "    pw_utils.detection_folder_separation(\n",
    "        json_file, tgt_folder_path, batch_output_path, threshold=0.5\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: Type - <class 'list'>, Length - 3\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, batch in enumerate(loader):\n",
    "    print(f\"Batch {batch_idx}: Type - {type(batch)}, Length - {len(batch)}\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'tuple'>\n",
      "Length: 3\n",
      "Contents: (tensor([[[0.4471, 0.4471, 0.4471,  ..., 0.4471, 0.4471, 0.4471],\n",
      "         [0.4471, 0.4471, 0.4471,  ..., 0.4471, 0.4471, 0.4471],\n",
      "         [0.4471, 0.4471, 0.4471,  ..., 0.4471, 0.4471, 0.4471],\n",
      "         ...,\n",
      "         [0.4471, 0.4471, 0.4471,  ..., 0.4471, 0.4471, 0.4471],\n",
      "         [0.4471, 0.4471, 0.4471,  ..., 0.4471, 0.4471, 0.4471],\n",
      "         [0.4471, 0.4471, 0.4471,  ..., 0.4471, 0.4471, 0.4471]],\n",
      "\n",
      "        [[0.4471, 0.4471, 0.4471,  ..., 0.4471, 0.4471, 0.4471],\n",
      "         [0.4471, 0.4471, 0.4471,  ..., 0.4471, 0.4471, 0.4471],\n",
      "         [0.4471, 0.4471, 0.4471,  ..., 0.4471, 0.4471, 0.4471],\n",
      "         ...,\n",
      "         [0.4471, 0.4471, 0.4471,  ..., 0.4471, 0.4471, 0.4471],\n",
      "         [0.4471, 0.4471, 0.4471,  ..., 0.4471, 0.4471, 0.4471],\n",
      "         [0.4471, 0.4471, 0.4471,  ..., 0.4471, 0.4471, 0.4471]],\n",
      "\n",
      "        [[0.4471, 0.4471, 0.4471,  ..., 0.4471, 0.4471, 0.4471],\n",
      "         [0.4471, 0.4471, 0.4471,  ..., 0.4471, 0.4471, 0.4471],\n",
      "         [0.4471, 0.4471, 0.4471,  ..., 0.4471, 0.4471, 0.4471],\n",
      "         ...,\n",
      "         [0.4471, 0.4471, 0.4471,  ..., 0.4471, 0.4471, 0.4471],\n",
      "         [0.4471, 0.4471, 0.4471,  ..., 0.4471, 0.4471, 0.4471],\n",
      "         [0.4471, 0.4471, 0.4471,  ..., 0.4471, 0.4471, 0.4471]]]), '/media/mo/nvme0n1/MDv5_v6_test_HG/O15/CAM136/17102023/100_BTCF/IMG_0022.JPG', tensor([1080, 1920]))\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the first item from the dataset\n",
    "first_item = dataset[0]\n",
    "print(f\"Type: {type(first_item)}\")\n",
    "print(f\"Length: {len(first_item)}\")\n",
    "print(f\"Contents: {first_item}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-wildlife",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
