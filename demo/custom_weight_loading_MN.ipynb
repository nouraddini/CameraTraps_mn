{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcc9460d-9d9e-4244-8283-64d1085f1ac6",
   "metadata": {},
   "source": [
    "# Custom Classification weight loading with PytorchWildlife"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1197e180",
   "metadata": {},
   "source": [
    "This tutorial guides you on how to use PyTorchWildlife for custom weight loading. We will go through the process of setting up the environment, defining the detection model, defining the custom classification model, as well as performing inference and saving the results in different ways.\n",
    "\n",
    "## Prerequisites\n",
    "Install PytorchWildlife running the following commands:\n",
    "```bash\n",
    "conda create -n pytorch_wildlife python=3.8 -y\n",
    "conda activate pytorch_wildlife\n",
    "pip install PytorchWildlife\n",
    "pip install wget\n",
    "```\n",
    "Also, make sure you have a CUDA-capable GPU if you intend to run the model on a GPU. This notebook can also run on CPU.\n",
    "\n",
    "## Importing libraries\n",
    "First, we'll start by importing the necessary libraries and modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee57bf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"..\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c44e7713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from PytorchWildlife.models import detection as pw_detection\n",
    "from PytorchWildlife.models import classification as pw_classification\n",
    "from PytorchWildlife.data import transforms as pw_trans\n",
    "from PytorchWildlife.data import datasets as pw_data \n",
    "from PytorchWildlife import utils as pw_utils\n",
    "import wget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abd07b5",
   "metadata": {},
   "source": [
    "## Model Initialization\n",
    "We will initialize the MegaDetectorV6 model for image detection. This model is designed for detecting animals in images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb25db43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.28 ðŸš€ Python-3.8.20 torch-2.4.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4090, 24217MiB)\n",
      "YOLOv9c summary (fused): 384 layers, 25,321,561 parameters, 0 gradients, 102.3 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "# Setting the device to use for computations ('cuda' indicates GPU)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if DEVICE == \"cuda\":\n",
    "    torch.cuda.set_device(0)\n",
    "\n",
    "detection_model = pw_detection.MegaDetectorV6(device=DEVICE, pretrained=True, version=\"yolov9c\")\n",
    "\n",
    "# Uncomment the following line to use MegaDetectorV5 instead of MegaDetectorV6\n",
    "#detection_model = pw_detection.MegaDetectorV5(device=DEVICE, pretrained=True, version=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b10a129f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the classification model\n",
    "example_weights = \"https://zenodo.org/records/13357337/files/AI4GAmazonClassification_v0.0.0.ckpt?download=1\"\n",
    "filename = wget.download(example_weights)\n",
    "class_names = {\n",
    "        0: 'Dasyprocta',\n",
    "        1: 'Bos',\n",
    "        2: 'Pecari',\n",
    "        3: 'Mazama',\n",
    "        4: 'Cuniculus',\n",
    "        5: 'Leptotila',\n",
    "        6: 'Human',\n",
    "        7: 'Aramides',\n",
    "        8: 'Tinamus',\n",
    "        9: 'Eira',\n",
    "        10: 'Crax',\n",
    "        11: 'Procyon',\n",
    "        12: 'Capra',\n",
    "        13: 'Dasypus',\n",
    "        14: 'Sciurus',\n",
    "        15: 'Crypturellus',\n",
    "        16: 'Tamandua',\n",
    "        17: 'Proechimys',\n",
    "        18: 'Leopardus',\n",
    "        19: 'Equus',\n",
    "        20: 'Columbina',\n",
    "        21: 'Nyctidromus',\n",
    "        22: 'Ortalis',\n",
    "        23: 'Emballonura',\n",
    "        24: 'Odontophorus',\n",
    "        25: 'Geotrygon',\n",
    "        26: 'Metachirus',\n",
    "        27: 'Catharus',\n",
    "        28: 'Cerdocyon',\n",
    "        29: 'Momotus',\n",
    "        30: 'Tapirus',\n",
    "        31: 'Canis',\n",
    "        32: 'Furnarius',\n",
    "        33: 'Didelphis',\n",
    "        34: 'Sylvilagus',\n",
    "        35: 'Unknown'\n",
    "    }\n",
    "\n",
    "classification_model = pw_classification.CustomWeights(weights=filename, class_names=class_names, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d730b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 2 animals, 30.2ms\n",
      "Speed: 2.1ms preprocess, 30.2ms inference, 236.4ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "tgt_img_path = os.path.join(\".\",\"demo_data\",\"imgs\",\"10050028_0.JPG\")\n",
    "img = np.array(Image.open(tgt_img_path).convert(\"RGB\"))\n",
    "results = detection_model.single_image_detection(img, tgt_img_path)\n",
    "pw_utils.save_detection_images(results, os.path.join(\".\",\"demo_output\"), overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e23329c",
   "metadata": {},
   "source": [
    "## Batch Image Detection\n",
    "Next, we'll demonstrate how to process multiple images in batches. This is useful when you have a large number of images and want to process them efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "561eff0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/814 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 2.4ms\n",
      "1: 384x640 (no detections), 2.4ms\n",
      "2: 384x640 2 animals, 2.4ms\n",
      "3: 384x640 1 animal, 2.4ms\n",
      "4: 384x640 1 animal, 2.4ms\n",
      "5: 384x640 1 animal, 2.4ms\n",
      "6: 384x640 1 animal, 2.4ms\n",
      "7: 384x640 1 animal, 2.4ms\n",
      "8: 384x640 1 animal, 2.4ms\n",
      "9: 384x640 1 animal, 2.4ms\n",
      "10: 384x640 1 animal, 2.4ms\n",
      "11: 384x640 1 animal, 2.4ms\n",
      "12: 384x640 1 animal, 2.4ms\n",
      "13: 384x640 1 animal, 2.4ms\n",
      "14: 384x640 1 animal, 2.4ms\n",
      "15: 384x640 1 animal, 2.4ms\n",
      "16: 384x640 1 animal, 2.4ms\n",
      "17: 384x640 1 animal, 2.4ms\n",
      "18: 384x640 1 animal, 2.4ms\n",
      "19: 384x640 1 animal, 2.4ms\n",
      "20: 384x640 1 animal, 2.4ms\n",
      "21: 384x640 1 animal, 2.4ms\n",
      "22: 384x640 1 animal, 2.4ms\n",
      "23: 384x640 1 animal, 2.4ms\n",
      "24: 384x640 1 animal, 2.4ms\n",
      "25: 384x640 2 animals, 2.4ms\n",
      "26: 384x640 5 animals, 2.4ms\n",
      "27: 384x640 5 animals, 2.4ms\n",
      "28: 384x640 7 animals, 2.4ms\n",
      "29: 384x640 4 animals, 2.4ms\n",
      "30: 384x640 5 animals, 2.4ms\n",
      "31: 384x640 6 animals, 2.4ms\n",
      "32: 384x640 6 animals, 2.4ms\n",
      "33: 384x640 6 animals, 2.4ms\n",
      "34: 384x640 7 animals, 2.4ms\n",
      "35: 384x640 8 animals, 2.4ms\n",
      "36: 384x640 8 animals, 2.4ms\n",
      "37: 384x640 7 animals, 2.4ms\n",
      "38: 384x640 5 animals, 2.4ms\n",
      "39: 384x640 5 animals, 2.4ms\n",
      "40: 384x640 6 animals, 2.4ms\n",
      "41: 384x640 1 animal, 2.4ms\n",
      "42: 384x640 1 animal, 2.4ms\n",
      "43: 384x640 (no detections), 2.4ms\n",
      "44: 384x640 2 animals, 2.4ms\n",
      "45: 384x640 (no detections), 2.4ms\n",
      "46: 384x640 (no detections), 2.4ms\n",
      "47: 384x640 1 animal, 2.4ms\n",
      "48: 384x640 1 animal, 2.4ms\n",
      "49: 384x640 1 animal, 2.4ms\n",
      "50: 384x640 1 animal, 2.4ms\n",
      "51: 384x640 (no detections), 2.4ms\n",
      "52: 384x640 (no detections), 2.4ms\n",
      "53: 384x640 (no detections), 2.4ms\n",
      "54: 384x640 (no detections), 2.4ms\n",
      "55: 384x640 (no detections), 2.4ms\n",
      "56: 384x640 1 animal, 2.4ms\n",
      "57: 384x640 (no detections), 2.4ms\n",
      "58: 384x640 1 animal, 2.4ms\n",
      "59: 384x640 (no detections), 2.4ms\n",
      "60: 384x640 (no detections), 2.4ms\n",
      "61: 384x640 1 animal, 2.4ms\n",
      "62: 384x640 1 animal, 2.4ms\n",
      "63: 384x640 (no detections), 2.4ms\n",
      "64: 384x640 (no detections), 2.4ms\n",
      "65: 384x640 1 animal, 2.4ms\n",
      "66: 384x640 1 animal, 2.4ms\n",
      "67: 384x640 (no detections), 2.4ms\n",
      "68: 384x640 (no detections), 2.4ms\n",
      "69: 384x640 1 animal, 2.4ms\n",
      "70: 384x640 (no detections), 2.4ms\n",
      "71: 384x640 (no detections), 2.4ms\n",
      "72: 384x640 1 animal, 2.4ms\n",
      "73: 384x640 2 animals, 2.4ms\n",
      "74: 384x640 1 animal, 2.4ms\n",
      "75: 384x640 1 animal, 2.4ms\n",
      "76: 384x640 2 animals, 2.4ms\n",
      "77: 384x640 1 animal, 2.4ms\n",
      "78: 384x640 1 animal, 2.4ms\n",
      "79: 384x640 1 animal, 2.4ms\n",
      "80: 384x640 1 animal, 2.4ms\n",
      "81: 384x640 1 animal, 2.4ms\n",
      "82: 384x640 (no detections), 2.4ms\n",
      "83: 384x640 (no detections), 2.4ms\n",
      "84: 384x640 1 animal, 2.4ms\n",
      "85: 384x640 1 animal, 2.4ms\n",
      "86: 384x640 1 animal, 2.4ms\n",
      "87: 384x640 1 animal, 2.4ms\n",
      "88: 384x640 1 animal, 2.4ms\n",
      "89: 384x640 4 animals, 2.4ms\n",
      "90: 384x640 4 animals, 2.4ms\n",
      "91: 384x640 5 animals, 2.4ms\n",
      "92: 384x640 5 animals, 2.4ms\n",
      "93: 384x640 5 animals, 2.4ms\n",
      "94: 384x640 6 animals, 2.4ms\n",
      "95: 384x640 5 animals, 2.4ms\n",
      "96: 384x640 7 animals, 2.4ms\n",
      "97: 384x640 6 animals, 2.4ms\n",
      "98: 384x640 5 animals, 2.4ms\n",
      "99: 384x640 7 animals, 2.4ms\n",
      "Speed: 0.9ms preprocess, 2.4ms inference, 0.2ms postprocess per image at shape (100, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/814 [00:04<1:05:42,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 6 animals, 2.4ms\n",
      "1: 384x640 7 animals, 2.4ms\n",
      "2: 384x640 7 animals, 2.4ms\n",
      "3: 384x640 7 animals, 2.4ms\n",
      "4: 384x640 1 animal, 2.4ms\n",
      "5: 384x640 1 animal, 2.4ms\n",
      "6: 384x640 1 animal, 2.4ms\n",
      "7: 384x640 1 animal, 2.4ms\n",
      "8: 384x640 1 animal, 2.4ms\n",
      "9: 384x640 2 animals, 2.4ms\n",
      "10: 384x640 2 animals, 2.4ms\n",
      "11: 384x640 2 animals, 2.4ms\n",
      "12: 384x640 2 animals, 2.4ms\n",
      "13: 384x640 2 animals, 2.4ms\n",
      "14: 384x640 1 animal, 2.4ms\n",
      "15: 384x640 1 animal, 2.4ms\n",
      "16: 384x640 1 animal, 2.4ms\n",
      "17: 384x640 1 animal, 2.4ms\n",
      "18: 384x640 1 animal, 2.4ms\n",
      "19: 384x640 1 animal, 2.4ms\n",
      "20: 384x640 1 animal, 2.4ms\n",
      "21: 384x640 1 animal, 2.4ms\n",
      "22: 384x640 1 animal, 2.4ms\n",
      "23: 384x640 1 animal, 2.4ms\n",
      "24: 384x640 1 animal, 2.4ms\n",
      "25: 384x640 1 animal, 2.4ms\n",
      "26: 384x640 1 animal, 2.4ms\n",
      "27: 384x640 1 animal, 2.4ms\n",
      "28: 384x640 1 animal, 2.4ms\n",
      "29: 384x640 1 animal, 2.4ms\n",
      "30: 384x640 1 animal, 2.4ms\n",
      "31: 384x640 1 animal, 2.4ms\n",
      "32: 384x640 1 animal, 2.4ms\n",
      "33: 384x640 1 animal, 2.4ms\n",
      "34: 384x640 1 animal, 2.4ms\n",
      "35: 384x640 1 animal, 2.4ms\n",
      "36: 384x640 1 animal, 2.4ms\n",
      "37: 384x640 1 animal, 2.4ms\n",
      "38: 384x640 1 animal, 2.4ms\n",
      "39: 384x640 1 animal, 2.4ms\n",
      "40: 384x640 1 animal, 2.4ms\n",
      "41: 384x640 1 animal, 2.4ms\n",
      "42: 384x640 1 animal, 2.4ms\n",
      "43: 384x640 1 animal, 2.4ms\n",
      "44: 384x640 1 animal, 2.4ms\n",
      "45: 384x640 1 person, 2.4ms\n",
      "46: 384x640 (no detections), 2.4ms\n",
      "47: 384x640 (no detections), 2.4ms\n",
      "48: 384x640 (no detections), 2.4ms\n",
      "49: 384x640 1 animal, 2.4ms\n",
      "50: 384x640 1 animal, 2.4ms\n",
      "51: 384x640 1 animal, 2.4ms\n",
      "52: 384x640 1 animal, 2.4ms\n",
      "53: 384x640 1 animal, 2.4ms\n",
      "54: 384x640 1 animal, 2.4ms\n",
      "55: 384x640 1 animal, 2.4ms\n",
      "56: 384x640 1 animal, 2.4ms\n",
      "57: 384x640 1 animal, 2.4ms\n",
      "58: 384x640 1 animal, 2.4ms\n",
      "59: 384x640 1 animal, 2.4ms\n",
      "60: 384x640 1 animal, 2.4ms\n",
      "61: 384x640 1 animal, 2.4ms\n",
      "62: 384x640 (no detections), 2.4ms\n",
      "63: 384x640 (no detections), 2.4ms\n",
      "64: 384x640 1 person, 2.4ms\n",
      "65: 384x640 1 animal, 2.4ms\n",
      "66: 384x640 1 animal, 2.4ms\n",
      "67: 384x640 1 animal, 2.4ms\n",
      "68: 384x640 1 animal, 2.4ms\n",
      "69: 384x640 1 animal, 2.4ms\n",
      "70: 384x640 1 animal, 2.4ms\n",
      "71: 384x640 1 animal, 2.4ms\n",
      "72: 384x640 1 animal, 2.4ms\n",
      "73: 384x640 1 animal, 2.4ms\n",
      "74: 384x640 1 animal, 2.4ms\n",
      "75: 384x640 1 animal, 2.4ms\n",
      "76: 384x640 1 animal, 2.4ms\n",
      "77: 384x640 1 animal, 2.4ms\n",
      "78: 384x640 1 person, 2.4ms\n",
      "79: 384x640 1 animal, 2.4ms\n",
      "80: 384x640 1 animal, 2.4ms\n",
      "81: 384x640 1 animal, 2.4ms\n",
      "82: 384x640 1 animal, 2.4ms\n",
      "83: 384x640 1 animal, 2.4ms\n",
      "84: 384x640 1 animal, 2.4ms\n",
      "85: 384x640 1 animal, 2.4ms\n",
      "86: 384x640 1 animal, 2.4ms\n",
      "87: 384x640 1 animal, 2.4ms\n",
      "88: 384x640 1 animal, 2.4ms\n",
      "89: 384x640 1 animal, 2.4ms\n",
      "90: 384x640 1 animal, 2.4ms\n",
      "91: 384x640 1 animal, 2.4ms\n",
      "92: 384x640 1 animal, 2.4ms\n",
      "93: 384x640 1 animal, 2.4ms\n",
      "94: 384x640 1 animal, 2.4ms\n",
      "95: 384x640 1 animal, 2.4ms\n",
      "96: 384x640 1 animal, 2.4ms\n",
      "97: 384x640 1 animal, 2.4ms\n",
      "98: 384x640 1 animal, 2.4ms\n",
      "99: 384x640 1 animal, 2.4ms\n",
      "Speed: 0.9ms preprocess, 2.4ms inference, 0.3ms postprocess per image at shape (100, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/814 [00:09<1:03:33,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 animal, 2.4ms\n",
      "1: 384x640 1 animal, 2.4ms\n",
      "2: 384x640 1 animal, 2.4ms\n",
      "3: 384x640 1 animal, 2.4ms\n",
      "4: 384x640 1 animal, 2.4ms\n",
      "5: 384x640 1 animal, 2.4ms\n",
      "6: 384x640 1 animal, 2.4ms\n",
      "7: 384x640 1 animal, 2.4ms\n",
      "8: 384x640 1 animal, 2.4ms\n",
      "9: 384x640 1 animal, 2.4ms\n",
      "10: 384x640 1 animal, 2.4ms\n",
      "11: 384x640 1 animal, 2.4ms\n",
      "12: 384x640 1 animal, 2.4ms\n",
      "13: 384x640 1 animal, 2.4ms\n",
      "14: 384x640 (no detections), 2.4ms\n",
      "15: 384x640 (no detections), 2.4ms\n",
      "16: 384x640 1 animal, 2.4ms\n",
      "17: 384x640 1 animal, 2.4ms\n",
      "18: 384x640 1 animal, 2.4ms\n",
      "19: 384x640 1 animal, 2.4ms\n",
      "20: 384x640 2 animals, 2.4ms\n",
      "21: 384x640 1 animal, 2.4ms\n",
      "22: 384x640 1 animal, 2.4ms\n",
      "23: 384x640 1 animal, 2.4ms\n",
      "24: 384x640 1 animal, 2.4ms\n",
      "25: 384x640 1 animal, 2.4ms\n",
      "26: 384x640 1 animal, 2.4ms\n",
      "27: 384x640 1 animal, 2.4ms\n",
      "28: 384x640 1 animal, 2.4ms\n",
      "29: 384x640 2 animals, 2.4ms\n",
      "30: 384x640 2 animals, 2.4ms\n",
      "31: 384x640 2 animals, 2.4ms\n",
      "32: 384x640 1 animal, 2.4ms\n",
      "33: 384x640 1 animal, 2.4ms\n",
      "34: 384x640 (no detections), 2.4ms\n",
      "35: 384x640 2 animals, 2.4ms\n",
      "36: 384x640 1 animal, 2.4ms\n",
      "37: 384x640 (no detections), 2.4ms\n",
      "38: 384x640 1 animal, 2.4ms\n",
      "39: 384x640 1 animal, 2.4ms\n",
      "40: 384x640 1 animal, 2.4ms\n",
      "41: 384x640 1 animal, 2.4ms\n",
      "42: 384x640 1 animal, 2.4ms\n",
      "43: 384x640 1 animal, 2.4ms\n",
      "44: 384x640 1 animal, 2.4ms\n",
      "45: 384x640 1 animal, 2.4ms\n",
      "46: 384x640 1 animal, 2.4ms\n",
      "47: 384x640 1 animal, 2.4ms\n",
      "48: 384x640 1 animal, 2.4ms\n",
      "49: 384x640 1 animal, 2.4ms\n",
      "50: 384x640 1 animal, 2.4ms\n",
      "51: 384x640 1 animal, 2.4ms\n",
      "52: 384x640 1 animal, 2.4ms\n",
      "53: 384x640 1 animal, 2.4ms\n",
      "54: 384x640 (no detections), 2.4ms\n",
      "55: 384x640 1 animal, 2.4ms\n",
      "56: 384x640 1 animal, 2.4ms\n",
      "57: 384x640 1 animal, 2.4ms\n",
      "58: 384x640 (no detections), 2.4ms\n",
      "59: 384x640 (no detections), 2.4ms\n",
      "60: 384x640 (no detections), 2.4ms\n",
      "61: 384x640 (no detections), 2.4ms\n",
      "62: 384x640 1 animal, 2.4ms\n",
      "63: 384x640 1 animal, 2.4ms\n",
      "64: 384x640 1 animal, 2.4ms\n",
      "65: 384x640 1 animal, 2.4ms\n",
      "66: 384x640 1 animal, 2.4ms\n",
      "67: 384x640 1 animal, 2.4ms\n",
      "68: 384x640 1 animal, 2.4ms\n",
      "69: 384x640 1 animal, 2.4ms\n",
      "70: 384x640 (no detections), 2.4ms\n",
      "71: 384x640 1 animal, 2.4ms\n",
      "72: 384x640 1 animal, 2.4ms\n",
      "73: 384x640 1 animal, 2.4ms\n",
      "74: 384x640 1 animal, 2.4ms\n",
      "75: 384x640 1 animal, 2.4ms\n",
      "76: 384x640 1 animal, 2.4ms\n",
      "77: 384x640 1 animal, 2.4ms\n",
      "78: 384x640 1 animal, 2.4ms\n",
      "79: 384x640 1 animal, 2.4ms\n",
      "80: 384x640 1 animal, 2.4ms\n",
      "81: 384x640 1 animal, 2.4ms\n",
      "82: 384x640 1 animal, 2.4ms\n",
      "83: 384x640 1 animal, 2.4ms\n",
      "84: 384x640 1 animal, 2.4ms\n",
      "85: 384x640 1 animal, 2.4ms\n",
      "86: 384x640 (no detections), 2.4ms\n",
      "87: 384x640 (no detections), 2.4ms\n",
      "88: 384x640 (no detections), 2.4ms\n",
      "89: 384x640 (no detections), 2.4ms\n",
      "90: 384x640 (no detections), 2.4ms\n",
      "91: 384x640 (no detections), 2.4ms\n",
      "92: 384x640 (no detections), 2.4ms\n",
      "93: 384x640 6 animals, 2.4ms\n",
      "94: 384x640 7 animals, 2.4ms\n",
      "95: 384x640 6 animals, 2.4ms\n",
      "96: 384x640 7 animals, 2.4ms\n",
      "97: 384x640 5 animals, 2.4ms\n",
      "98: 384x640 4 animals, 2.4ms\n",
      "99: 384x640 3 animals, 2.4ms\n",
      "Speed: 0.9ms preprocess, 2.4ms inference, 0.2ms postprocess per image at shape (100, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/814 [00:13<57:10,  4.23s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/814 [00:16<1:16:02,  5.63s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m tgt_folder_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/media/mo/nvme0n1/Wildlife_test_HG\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#det_results = detection_model.batch_image_detection(tgt_folder_path, batch_size=16, extension=\"JPG\")\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m det_results \u001b[38;5;241m=\u001b[39m \u001b[43mdetection_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_image_detection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtgt_folder_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CameraTraps/PytorchWildlife/models/detection/ultralytics_based/yolov8_base.py:184\u001b[0m, in \u001b[0;36mYOLOV8Base.batch_image_detection\u001b[0;34m(self, data_path, batch_size, conf_thres, id_strip)\u001b[0m\n\u001b[1;32m    182\u001b[0m det_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mstream_inference(paths)\n\u001b[1;32m    183\u001b[0m batch_results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 184\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, preds \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(det_results):\n\u001b[1;32m    185\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults_generation(preds, paths[idx], id_strip)\n\u001b[1;32m    186\u001b[0m     size \u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39morig_shape\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-wildlife/lib/python3.8/site-packages/torch/utils/_contextlib.py:36\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m---> 36\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-wildlife/lib/python3.8/site-packages/ultralytics/engine/predictor.py:262\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;66;03m# Postprocess\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m2\u001b[39m]:\n\u001b[0;32m--> 262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpostprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mim0s\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_callbacks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_predict_postprocess_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# Visualize, save, write results\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-wildlife/lib/python3.8/site-packages/ultralytics/models/yolo/detect/predict.py:25\u001b[0m, in \u001b[0;36mDetectionPredictor.postprocess\u001b[0;34m(self, preds, img, orig_imgs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpostprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, preds, img, orig_imgs):\n\u001b[1;32m     24\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Post-processes predictions and returns a list of Results objects.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnon_max_suppression\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miou\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43magnostic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magnostic_nms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_det\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_det\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(orig_imgs, \u001b[38;5;28mlist\u001b[39m):  \u001b[38;5;66;03m# input images are a torch.Tensor, not a list\u001b[39;00m\n\u001b[1;32m     35\u001b[0m         orig_imgs \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_torch2numpy_batch(orig_imgs)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-wildlife/lib/python3.8/site-packages/ultralytics/utils/ops.py:271\u001b[0m, in \u001b[0;36mnon_max_suppression\u001b[0;34m(prediction, conf_thres, iou_thres, classes, agnostic, multi_label, labels, max_det, nc, max_time_img, max_nms, max_wh, in_place, rotated)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# best class only\u001b[39;00m\n\u001b[1;32m    270\u001b[0m     conf, j \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 271\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconf_thres\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;66;03m# Filter by class\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m classes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#tgt_folder_path = os.path.join(\".\",\"demo_data\",\"imgs\")\n",
    "\n",
    "tgt_folder_path = \"/media/mo/nvme0n1/Wildlife_test_HG\"\n",
    "#det_results = detection_model.batch_image_detection(tgt_folder_path, batch_size=16, extension=\"JPG\")\n",
    "det_results = detection_model.batch_image_detection(tgt_folder_path, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1cbb9fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'det_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m clf_dataset \u001b[38;5;241m=\u001b[39m pw_data\u001b[38;5;241m.\u001b[39mDetectionCrops(\n\u001b[0;32m----> 2\u001b[0m             \u001b[43mdet_results\u001b[49m,\n\u001b[1;32m      3\u001b[0m             transform\u001b[38;5;241m=\u001b[39mpw_trans\u001b[38;5;241m.\u001b[39mClassification_Inference_Transform(target_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m224\u001b[39m),\n\u001b[1;32m      4\u001b[0m             path_head\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m         )\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#clf_loader = DataLoader(clf_dataset, batch_size=32, shuffle=False, \u001b[39;00m\n\u001b[1;32m      8\u001b[0m clf_loader \u001b[38;5;241m=\u001b[39m DataLoader(clf_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[1;32m      9\u001b[0m                                 pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, drop_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'det_results' is not defined"
     ]
    }
   ],
   "source": [
    "clf_dataset = pw_data.DetectionCrops(\n",
    "            det_results,\n",
    "            transform=pw_trans.Classification_Inference_Transform(target_size=224),\n",
    "            path_head=\"\"\n",
    "        )\n",
    "\n",
    "#clf_loader = DataLoader(clf_dataset, batch_size=32, shuffle=False, \n",
    "clf_loader = DataLoader(clf_dataset, batch_size=16, shuffle=False, \n",
    "                                pin_memory=True, num_workers=0, drop_last=False)\n",
    "clf_results = classification_model.batch_image_classification(clf_loader, id_strip=tgt_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e495f05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pw_utils.save_detection_classification_json(det_results=det_results,\n",
    "                                                        clf_results=clf_results,\n",
    "                                                        det_categories=detection_model.CLASS_NAMES,\n",
    "                                                        clf_categories=classification_model.CLASS_NAMES,\n",
    "                                                        output_path=\"results.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-wildlife",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
